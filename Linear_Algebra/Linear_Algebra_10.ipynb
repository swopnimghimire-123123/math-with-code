{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyORskk2+LGg2aynuz4szPPH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swopnimghimire-123123/Maths_For_ML/blob/main/Linear_Algebra_10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Eigenvectors and Eigenvalues\n",
        "\n",
        "###  Idea\n",
        "- For a square matrix **A**, an **eigenvector** v is a non-zero vector that **doesn’t change direction** when A is applied:  \n",
        "\\[\n",
        "A v = \\lambda v\n",
        "\\]  \n",
        "- Here, λ is the **eigenvalue** corresponding to eigenvector v.\n",
        "\n",
        "###  Geometric Meaning\n",
        "- Eigenvectors = directions that remain **unchanged under transformation A**.  \n",
        "- Eigenvalues = **scaling factor** along that direction.  \n",
        "- Example:\n",
        "  - If λ = 2, the vector **stretches by 2×**.  \n",
        "  - If λ = 1, the vector keeps its **length**.  \n",
        "  - If λ = -1, the vector **flips direction**.  \n",
        "\n",
        "###  How to Compute\n",
        "1. Solve the **characteristic equation**:  \n",
        "\\[\n",
        "\\det(A - \\lambda I) = 0\n",
        "\\]  \n",
        "2. Solve \\((A - \\lambda I)v = 0\\) for each λ to get eigenvectors.\n"
      ],
      "metadata": {
        "id": "TbluufecanPD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GfaD5FWaM5Q",
        "outputId": "97967cc4-01ad-44fe-e010-baa2d59dc358"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eigenvalues: [5. 2.]\n",
            "Eigenvectors (columns):\n",
            " [[ 0.70710678 -0.4472136 ]\n",
            " [ 0.70710678  0.89442719]]\n",
            "\n",
            "Checking eigenvector 1:\n",
            "A @ v = [3.53553391 3.53553391]\n",
            "λ * v  = [3.53553391 3.53553391]\n",
            "\n",
            "Checking eigenvector 2:\n",
            "A @ v = [-0.89442719  1.78885438]\n",
            "λ * v  = [-0.89442719  1.78885438]\n"
          ]
        }
      ],
      "source": [
        "#  Eigenvectors and Eigenvalues in Python\n",
        "import numpy as np\n",
        "\n",
        "# Example matrix\n",
        "A = np.array([[4, 1],\n",
        "              [2, 3]])\n",
        "\n",
        "# Compute eigenvalues and eigenvectors\n",
        "eigvals, eigvecs = np.linalg.eig(A)\n",
        "\n",
        "print(\"Eigenvalues:\", eigvals)\n",
        "print(\"Eigenvectors (columns):\\n\", eigvecs)\n",
        "\n",
        "# Verify: A*v = λ*v\n",
        "for i in range(len(eigvals)):\n",
        "    v = eigvecs[:,i]\n",
        "    lam = eigvals[i]\n",
        "    print(f\"\\nChecking eigenvector {i+1}:\")\n",
        "    print(\"A @ v =\", A @ v)\n",
        "    print(\"λ * v  =\", lam * v)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Key Takeaways:\n",
        "\n",
        "- Eigenvectors = directions preserved by A.\n",
        "\n",
        "- Eigenvalues = scaling along those directions.\n",
        "\n",
        "- Very useful in linear transformations, PCA, diagonalization, and physics problems."
      ],
      "metadata": {
        "id": "GQCLxWpWbk_d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Eigenvectors and Eigenvalues – Story Version\n",
        "\n",
        "Imagine you are in a 3D room with a **rubber sheet** floor.  \n",
        "- You can stretch, compress, or rotate the sheet. This is your **linear transformation A**.\n",
        "\n",
        "Now, you place arrows (vectors) on the sheet in different directions:  \n",
        "\n",
        "1. Most arrows **change direction** when the sheet is stretched or rotated.  \n",
        "2. Some special arrows, however, **point along directions that don’t rotate**.  \n",
        "   - These are the **eigenvectors**.  \n",
        "   - They may get longer or shorter, but they **stay pointing the same way**.\n",
        "\n",
        "The amount each eigenvector **stretches or shrinks** is the **eigenvalue λ**:  \n",
        "- λ > 1 → vector stretches  \n",
        "- 0 < λ < 1 → vector shrinks  \n",
        "- λ < 0 → vector flips direction  \n",
        "\n",
        "Mathematically:  \n",
        "\\[\n",
        "A v = \\lambda v\n",
        "\\]  \n",
        "- v = eigenvector  \n",
        "- λ = eigenvalue  \n",
        "\n",
        " **Key Idea:** Eigenvectors = “special directions that remain fixed in direction under transformation.”  \n",
        "Eigenvalues = “how much those directions get scaled.”\n"
      ],
      "metadata": {
        "id": "jrvgZgI1bu9u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Story Example\n",
        "import numpy as np\n",
        "\n",
        "# Example 3x3 matrix (transformation)\n",
        "A = np.array([[2, 0, 0],\n",
        "              [0, 3, 4],\n",
        "              [0, 4, 9]])\n",
        "\n",
        "# Compute eigenvalues and eigenvectors\n",
        "eigvals, eigvecs = np.linalg.eig(A)\n",
        "\n",
        "print(\"Eigenvalues:\", eigvals)\n",
        "print(\"Eigenvectors (columns):\\n\", eigvecs)\n",
        "\n",
        "# Verification: A*v = λ*v\n",
        "for i in range(len(eigvals)):\n",
        "    v = eigvecs[:,i]\n",
        "    lam = eigvals[i]\n",
        "    print(f\"\\nEigenvector {i+1}:\")\n",
        "    print(\"A @ v =\", A @ v)\n",
        "    print(\"λ * v  =\", lam * v)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJOBmHFDaQY4",
        "outputId": "57681985-466c-480b-f3f4-0e6848a46075"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eigenvalues: [11.  1.  2.]\n",
            "Eigenvectors (columns):\n",
            " [[ 0.          0.          1.        ]\n",
            " [ 0.4472136   0.89442719  0.        ]\n",
            " [ 0.89442719 -0.4472136   0.        ]]\n",
            "\n",
            "Eigenvector 1:\n",
            "A @ v = [0.         4.91934955 9.8386991 ]\n",
            "λ * v  = [0.         4.91934955 9.8386991 ]\n",
            "\n",
            "Eigenvector 2:\n",
            "A @ v = [ 0.          0.89442719 -0.4472136 ]\n",
            "λ * v  = [ 0.          0.89442719 -0.4472136 ]\n",
            "\n",
            "Eigenvector 3:\n",
            "A @ v = [2. 0. 0.]\n",
            "λ * v  = [2. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Story Takeaways:\n",
        "\n",
        "- Most vectors twist or move under transformation.\n",
        "\n",
        "- Eigenvectors are the “safe arrows” that don’t rotate.\n",
        "\n",
        "- Eigenvalues tell how much those arrows stretch or flip."
      ],
      "metadata": {
        "id": "TsGXkLj5c0Jg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Verification of Eigenvectors and Eigenvalues\n",
        "\n",
        "###  Goal\n",
        "After computing eigenvectors `v` and eigenvalues `λ` for a matrix `A`, we verify that:\n",
        "\n",
        "\\[\n",
        "A v = \\lambda v\n",
        "\\]\n",
        "\n",
        "- This confirms that applying the transformation `A` to `v` **only scales it**, without changing its direction.\n",
        "\n",
        "---\n",
        "\n",
        "###  Step-by-Step Verification\n",
        "1. Take one eigenvector `v` (a column from `eigvecs`).  \n",
        "2. Multiply it by the matrix `A`: `A @ v`.  \n",
        "   - This simulates **applying the linear transformation** to `v`.  \n",
        "3. Multiply the same eigenvector by its corresponding eigenvalue `λ`: `λ * v`.  \n",
        "4. Compare the two results.  \n",
        "   - If they match (or are very close numerically), `v` is truly an eigenvector and `λ` its eigenvalue.  \n",
        "\n",
        " Intuition:  \n",
        "- Think of `v` as an arrow in space.  \n",
        "- Applying `A` stretches or flips the arrow, but **keeps it pointing in the same direction**.  \n",
        "- `λ` tells you **how much it stretches or flips**.\n"
      ],
      "metadata": {
        "id": "FoewoX5ddOBz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Extra Insights on Eigenvectors and Eigenvalues\n",
        "\n",
        "1. **Eigenvectors are not unique in length**  \n",
        "   - Any scalar multiple of an eigenvector is also an eigenvector.  \n",
        "   - Only the **direction matters**, not the magnitude.\n",
        "\n",
        "2. **Multiplicity**  \n",
        "   - An eigenvalue can correspond to **more than one independent eigenvector** (geometric multiplicity).  \n",
        "   - All these eigenvectors lie along directions that remain invariant under the transformation.\n",
        "\n",
        "3. **Diagonalization**  \n",
        "   - If a matrix has **n independent eigenvectors**, you can form a matrix P of these eigenvectors.  \n",
        "   - Then:  \n",
        "     \\[\n",
        "     P^{-1} A P = D\n",
        "     \\]  \n",
        "     where D is diagonal with eigenvalues.  \n",
        "   - This simplifies computations (powers of matrices, solving differential equations, etc.).\n",
        "\n",
        "4. **Physical meaning in applications**  \n",
        "   - **PCA in data science**: eigenvectors = principal directions of variance.  \n",
        "   - **Physics**: eigenvectors = natural vibration modes; eigenvalues = frequencies or energy levels.  \n",
        "   - **Graphics**: eigenvectors = invariant directions for transformations.\n",
        "\n",
        "5. **Verification**  \n",
        "   - Always check \\(A v = \\lambda v\\) numerically. Small differences can arise due to floating-point errors.\n",
        "\n",
        " **Summary**:  \n",
        "- Eigenvectors = “directions that don’t rotate under a transformation.”  \n",
        "- Eigenvalues = “how much those directions stretch or flip.”  \n",
        "- Useful in **diagonalization, PCA, physics, and simplifying transformations**.\n"
      ],
      "metadata": {
        "id": "UxC15C66ekRn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Trick to compute eigen values"
      ],
      "metadata": {
        "id": "fbR0brdxfLWZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  3-Step Quick Eigenvalue Formula for 2x2 Matrix\n",
        "\n",
        "For a 2x2 matrix A = [[a, b], [c, d]]:\n",
        "\n",
        "1. **Mean of diagonals**:  \n",
        "   m = (a + d) / 2  \n",
        "\n",
        "2. **Determinant**:  \n",
        "   p = ad - bc  \n",
        "\n",
        "3. **Eigenvalues**:  \n",
        "   λ₁, λ₂ = m ± sqrt(m² - p)\n"
      ],
      "metadata": {
        "id": "KzAXYzPfhcM2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# define a 2X2 matrix\n",
        "\n",
        "A = np.array([[4,2],[1,3]], dtype = float)\n",
        "\n",
        "print(\"Matrix A:\\n\",A)\n",
        "\n",
        "# step:1 compute trace and mean\n",
        "trace = np.trace(A)\n",
        "print(\"TRACE\",trace)\n",
        "mean = trace / 2\n",
        "print(\"MEAN:\",mean,\"\\n\")\n",
        "\n",
        "# step:2 compute the determinant\n",
        "det = np.linalg.det(A)\n",
        "print(\"DETERMINANT:\",det,\"\\n\")\n",
        "\n",
        "# step:3 compute the sqrt term (m^2 - p)\n",
        "sqrt_term = np.sqrt(mean**2 - det)\n",
        "print(\"square root term of the last step :\",sqrt_term)\n",
        "\n",
        "# step:4 compute the eigenvalues\n",
        "eig1 = mean + sqrt_term\n",
        "eig2 = mean - sqrt_term\n",
        "\n",
        "print(\"Eigenvalues:\",eig1,eig2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHG8eZmBaQbd",
        "outputId": "2b1d804b-c6c5-45b3-fb77-1cd61aa666b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix A:\n",
            " [[4. 2.]\n",
            " [1. 3.]]\n",
            "TRACE 7.0\n",
            "MEAN: 3.5 \n",
            "\n",
            "DETERMINANT: 10.000000000000002 \n",
            "\n",
            "square root term of the last step : 1.4999999999999993\n",
            "Eigenvalues: 4.999999999999999 2.000000000000001\n"
          ]
        }
      ]
    }
  ]
}
